{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_habitat_map(map_size=(200,200), num_objects=10, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    habitat_map = np.zeros(map_size, dtype=np.uint8)  # Grayscale map (0: empty space)\n",
    "\n",
    "    for object_id in range(1, num_objects + 1):\n",
    "        shape = np.random.choice(['rectangle', 'circle'])\n",
    "\n",
    "        if shape == 'rectangle':\n",
    "            w, h = np.random.randint(10, 50), np.random.randint(10, 50)  # Random width and height\n",
    "            x, y = np.random.randint(0, map_size[1] - w), np.random.randint(0, map_size[0] - h)  # Random position\n",
    "            habitat_map[y:y+h, x:x+w] = object_id\n",
    "\n",
    "        elif shape == 'circle':\n",
    "            r = np.random.randint(3, 10)  # Random radius\n",
    "            cx, cy = np.random.randint(r, map_size[1] - r), np.random.randint(r, map_size[0] - r)  # Random center\n",
    "\n",
    "            for i in range(map_size[1]):\n",
    "                for j in range(map_size[0]):\n",
    "                    if (i - cy) ** 2 + (j - cx) ** 2 <= r ** 2:\n",
    "                        habitat_map[i, j] = object_id\n",
    "\n",
    "    return habitat_map\n",
    "\n",
    "# Generate the map\n",
    "seed = 23\n",
    "habitat_map = generate_habitat_map(seed=seed)\n",
    "\n",
    "# Save the map as a .npy file\n",
    "np.save(\"habitat_map.npy\", habitat_map)\n",
    "\n",
    "# Display the map\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(habitat_map, cmap='gray', interpolation='nearest')\n",
    "plt.colorbar(label=\"Object ID\")\n",
    "plt.title(\"Generated Habitat Map\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (2.5.0)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (2.6.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (3.9.4)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: pygame in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (6.1.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (13.9.4)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (0.10.1)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from stable-baselines3[extra]) (10.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (8.6.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.8.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.17.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (4.55.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from matplotlib->stable-baselines3[extra]) (6.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from importlib-metadata>=4.10.0->ale-py>=0.9.0->stable-baselines3[extra]) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"stable-baselines3[extra]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shimmy>=2.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from shimmy>=2.0) (1.26.4)\n",
      "Requirement already satisfied: gymnasium>=1.0.0a1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from shimmy>=2.0) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/envs/habitat/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gymnasium>=1.0.0a1->shimmy>=2.0) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shimmy\\>=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/habitat/lib/python3.9/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2e+03    |\n",
      "|    ep_rew_mean     | 322      |\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 210           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 295           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4480396e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.79         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 128           |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.000209     |\n",
      "|    value_loss           | 57.6          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 220           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 282           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00053050835 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.79         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 1.1           |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.00144      |\n",
      "|    value_loss           | 43.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 210          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019374398 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | -0.00014     |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 23.6         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 48.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 245          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 258          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018126329 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.00313      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 2.96         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 233          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014633845 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.0171       |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 4.77         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 77.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 213          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009979976 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.00929      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 3.35         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000978    |\n",
      "|    value_loss           | 71.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 243          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009967274 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 79.5         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    value_loss           | 54.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 261           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 238           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 77            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.0316227e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.78         |\n",
      "|    explained_variance   | -0.00618      |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 109           |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000149     |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 277           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 233           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 87            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014900879 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.77         |\n",
      "|    explained_variance   | 0.00848       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 12.3          |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.000446     |\n",
      "|    value_loss           | 122           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 272           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 229           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 97            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.8752724e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.78         |\n",
      "|    explained_variance   | 0.0079        |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 52.1          |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000311     |\n",
      "|    value_loss           | 125           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 288          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 227          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002750465 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | -0.00521     |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 38.9         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000974    |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 302           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 224           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 118           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018732296 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.78         |\n",
      "|    explained_variance   | 0.00801       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 15.2          |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.000474     |\n",
      "|    value_loss           | 169           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 317           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 222           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 128           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011438923 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.78         |\n",
      "|    explained_variance   | -0.00758      |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 76.3          |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.000626     |\n",
      "|    value_loss           | 149           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 329           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 219           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032729763 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.78         |\n",
      "|    explained_variance   | -0.00569      |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 56            |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.000658     |\n",
      "|    value_loss           | 167           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 323           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 219           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037261058 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.78         |\n",
      "|    explained_variance   | 0.00542       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 181           |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000558     |\n",
      "|    value_loss           | 165           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 321          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006085769 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | -0.00208     |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 31.6         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    value_loss           | 56           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 325           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 216           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 170           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013139754 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.78         |\n",
      "|    explained_variance   | -0.00473      |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 32.7          |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.00061      |\n",
      "|    value_loss           | 127           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 341          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003815725 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | 0.00092      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 45.8         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000638    |\n",
      "|    value_loss           | 196          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 342           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 214           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 191           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044691874 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.78         |\n",
      "|    explained_variance   | 0.00299       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 26.6          |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000642     |\n",
      "|    value_loss           | 197           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 343          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 213          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007204438 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | 0.0245       |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 7.94         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000611    |\n",
      "|    value_loss           | 76.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 350          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 212          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013672465 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | 0.00299      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 69.4         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 86.1         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2e+03     |\n",
      "|    ep_rew_mean          | 355       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 210       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 223       |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0010465 |\n",
      "|    clip_fraction        | 0.000586  |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.76     |\n",
      "|    explained_variance   | 0.0237    |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | 23.3      |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -0.00169  |\n",
      "|    value_loss           | 90        |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 361           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 209           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 235           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021513764 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.75         |\n",
      "|    explained_variance   | 0.0308        |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 27.5          |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.000444     |\n",
      "|    value_loss           | 191           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 356          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005038554 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.00126      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 33.1         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000432    |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 353          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010307783 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.00604      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 62.2         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 91.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 350          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 265          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003924796 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.00756      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 70.1         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000508    |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 354          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 276          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002771962 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.000586     |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 144          |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.000269    |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 358          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 286          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004770321 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.0243       |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 16.2         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000904    |\n",
      "|    value_loss           | 91.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 363          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 296          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.264646e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.00503      |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 8.37         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.000297    |\n",
      "|    value_loss           | 246          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2e+03         |\n",
      "|    ep_rew_mean          | 362           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 205           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 308           |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022576228 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.76         |\n",
      "|    explained_variance   | 0.00695       |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 95.2          |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.000543     |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "class ObjectHuntEnv(gym.Env):\n",
    "    def __init__(self, map_size=(200, 200), max_steps=2000, view_distance=20, view_angle=60, agent_size=(10,10), seed=None):\n",
    "        super(ObjectHuntEnv, self).__init__()\n",
    "        self.map_size = map_size\n",
    "        self.max_steps = max_steps\n",
    "        self.view_distance = view_distance\n",
    "        self.view_angle = view_angle\n",
    "        self.agent_size = agent_size\n",
    "\n",
    "        self.seed = seed\n",
    "        self.instance_map = self.generate_instance_map()\n",
    "\n",
    "        self.agent_pos = np.array(agent_size)\n",
    "        self.agent_dir = np.random.randint(0, 360)\n",
    "        self.collected_objects = set()\n",
    "        self.visited_positions = set()\n",
    "        self.steps = 0\n",
    "\n",
    "        self.action_space = spaces.Discrete(6)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(view_distance, view_distance, 1), dtype=np.uint8)\n",
    "\n",
    "    def generate_instance_map(self):\n",
    "        return generate_habitat_map(self.map_size, seed=seed)\n",
    "    \n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        prev_pos = self.agent_pos.copy()\n",
    "        width, height = self.agent_size\n",
    "        reward = 0\n",
    "\n",
    "        # Define movement logic considering agent size\n",
    "        if (action == 0 and prev_pos[0] - height // 2 - 1 >= 0 and \n",
    "            np.all(self.instance_map[prev_pos[0] - height // 2 - 1 : prev_pos[0] + height // 2 - 1, prev_pos[1] - width // 2 : prev_pos[1] + width // 2] == 0)):\n",
    "            self.agent_pos[0] -= 1  # Move up\n",
    "        elif (action == 1 and \n",
    "              prev_pos[0] + height // 2 + 1 < self.map_size[0] and \n",
    "              np.all(self.instance_map[prev_pos[0] - height // 2 + 1 : prev_pos[0] + height // 2 + 1, prev_pos[1] - width // 2 : prev_pos[1] + width // 2] == 0)):\n",
    "            self.agent_pos[0] += 1  # Move down\n",
    "        elif (action == 2 and prev_pos[1] - width // 2 - 1 >= 0 and \n",
    "              np.all(self.instance_map[prev_pos[0] - height // 2 : prev_pos[0] + height // 2, prev_pos[1] - width // 2 - 1 : prev_pos[1] + width // 2 - 1] == 0)):\n",
    "            self.agent_pos[1] -= 1  # Move left\n",
    "        elif (action == 3 and prev_pos[1] + width // 2 + 1 < self.map_size[1] and \n",
    "              np.all(self.instance_map[prev_pos[0] - height // 2 : prev_pos[0] + height // 2, prev_pos[1] - width // 2 + 1 : prev_pos[1] + width // 2 + 1] == 0)):\n",
    "            self.agent_pos[1] += 1  # Move right\n",
    "        elif action == 4:\n",
    "            self.agent_dir = (self.agent_dir - 15) % 360  # Rotate left\n",
    "        elif action == 5:\n",
    "            self.agent_dir = (self.agent_dir + 15) % 360  # Rotate right\n",
    "        else:\n",
    "            reward -= 1  # Penalize for hitting an obstacle\n",
    "\n",
    "        # if np.array_equal(self.agent_pos, prev_pos):  \n",
    "            # reward -= 2\n",
    "\n",
    "        visible_objects = self.get_visible_objects()\n",
    "        new_objects = visible_objects - self.collected_objects\n",
    "        self.collected_objects.update(new_objects)\n",
    "\n",
    "        if new_objects:\n",
    "            reward += 100 * len(new_objects)\n",
    "\n",
    "        if tuple(self.agent_pos) not in self.visited_positions:\n",
    "            self.visited_positions.add(tuple(self.agent_pos))\n",
    "            reward += 1000/self.max_steps\n",
    "\n",
    "        movement_distance = np.linalg.norm(self.agent_pos - prev_pos)\n",
    "        reward += movement_distance #reward for step (not rotation)\n",
    "\n",
    "        self.steps += 1\n",
    "        done = self.steps >= self.max_steps\n",
    "\n",
    "        return self.get_observation(), reward, done, {}\n",
    "\n",
    "    def get_visible_objects(self):\n",
    "        visible_objects = set()\n",
    "        cx, cy = self.agent_pos\n",
    "\n",
    "        for i in range(-self.view_distance, self.view_distance + 1):\n",
    "            for j in range(-self.view_distance, self.view_distance + 1):\n",
    "                x, y = cx + i, cy + j\n",
    "                if 0 <= x < self.map_size[0] and 0 <= y < self.map_size[1]:\n",
    "                    angle = np.degrees(np.arctan2(j, i)) % 360\n",
    "                    if abs((angle - self.agent_dir + 180) % 360 - 180) <= self.view_angle / 2:\n",
    "                        obj_id = self.instance_map[x, y]\n",
    "                        if obj_id > 0:\n",
    "                            visible_objects.add(obj_id)\n",
    "        return visible_objects\n",
    "\n",
    "    def get_observation(self):\n",
    "        obs = np.zeros((self.view_distance, self.view_distance), dtype=np.uint8)\n",
    "        cx, cy = self.agent_pos\n",
    "\n",
    "        for i in range(-self.view_distance // 2, self.view_distance // 2):\n",
    "            for j in range(-self.view_distance // 2, self.view_distance // 2):\n",
    "                x, y = cx + i, cy + j\n",
    "                if 0 <= x < self.map_size[0] and 0 <= y < self.map_size[1]:\n",
    "                    angle = np.degrees(np.arctan2(j, i)) % 360\n",
    "                    if abs((angle - self.agent_dir + 180) % 360 - 180) <= self.view_angle / 2:\n",
    "                        obs[i + self.view_distance // 2, j + self.view_distance // 2] = self.instance_map[x, y] > 0\n",
    "        return obs[..., np.newaxis]\n",
    "\n",
    "    def reset(self):\n",
    "    #   attempts = 0\n",
    "    #   max_attempts=100\n",
    "    #   while attempts < max_attempts:\n",
    "    #       # Randomly select a position ensuring it fits the agent's size\n",
    "    #       x = np.random.randint(self.agent_size[0] // 2, self.map_size[0] - self.agent_size[0] // 2)\n",
    "    #       y = np.random.randint(self.agent_size[1] // 2, self.map_size[1] - self.agent_size[1] // 2)\n",
    "\n",
    "    #       # Check if the area occupied by the agent is free\n",
    "    #       if np.all(self.instance_map[x - self.agent_size[0]// 2 : x + self.agent_size[0]// 2, \n",
    "    #                                   y - self.agent_size[1]//2 : y + self.agent_size[1]//2] == 0):\n",
    "    #           self.agent_pos = np.array([x, y])\n",
    "    #           break\n",
    "\n",
    "    #       attempts += 1\n",
    "\n",
    "      # Fallback position if no valid position is found\n",
    "    #  if attempts == max_attempts:\n",
    "      self.agent_pos = np.array(self.agent_size)  # Fallback position\n",
    "\n",
    "      self.agent_dir = np.random.randint(0, 360)\n",
    "      self.collected_objects.clear()\n",
    "      self.steps = 0\n",
    "      return self.get_observation()\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "      img = np.copy(self.instance_map)\n",
    "      img = (img / img.max() * 255).astype(np.uint8)\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "      # Draw agent's position\n",
    "      #cv2.circle(img, (self.agent_pos[1], self.agent_pos[0]), self.agent_size[0]//2, (0, 0, 255), -1)\n",
    "      cv2.rectangle(img, (self.agent_pos[1] - self.agent_size[0] // 2, self.agent_pos[0] - self.agent_size[1] // 2),  # Top-left corner\n",
    "                    (self.agent_pos[1] + self.agent_size[0] // 2, self.agent_pos[0] + self.agent_size[1] // 2),  # Bottom-right corner\n",
    "                    (0, 0, 255), -1)\n",
    "      # Draw direction of view\n",
    "      angle_rad = np.radians(self.agent_dir)\n",
    "      dx = int(self.view_distance * np.sin(angle_rad))\n",
    "      dy = int(self.view_distance * np.cos(angle_rad))\n",
    "\n",
    "      cv2.arrowedLine(img, (self.agent_pos[1], self.agent_pos[0]), (self.agent_pos[1] + dx, self.agent_pos[0] + dy), (255, 0, 0), thickness=1, tipLength=0.15)\n",
    "\n",
    "      # Calculate view angle boundaries\n",
    "      left_angle = np.radians(self.agent_dir - self.view_angle / 2)\n",
    "      right_angle = np.radians(self.agent_dir + self.view_angle / 2)\n",
    "\n",
    "      # Calculate end points of the view angle lines\n",
    "      left_dx = int(self.view_distance * np.sin(left_angle))\n",
    "      left_dy = int(self.view_distance * np.cos(left_angle))\n",
    "      right_dx = int(self.view_distance * np.sin(right_angle))\n",
    "      right_dy = int(self.view_distance * np.cos(right_angle))\n",
    "\n",
    "      # Draw view angle lines\n",
    "      cv2.line(img, (self.agent_pos[1], self.agent_pos[0]), (self.agent_pos[1] + left_dx, self.agent_pos[0] + left_dy), (0, 255, 0), 1)\n",
    "      cv2.line(img, (self.agent_pos[1], self.agent_pos[0]), (self.agent_pos[1] + right_dx, self.agent_pos[0] + right_dy), (0, 255, 0), 1)\n",
    "\n",
    "      visible_objects = self.get_visible_objects()\n",
    "\n",
    "\n",
    "      for obj_id in self.collected_objects:\n",
    "          bbox = self.get_object_bbox(obj_id)\n",
    "          if bbox is not None:\n",
    "              cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 255), 1)\n",
    "\n",
    "      for obj_id in visible_objects:\n",
    "          bbox = self.get_object_bbox(obj_id)  \n",
    "          if bbox is not None:\n",
    "              cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 1)  \n",
    "\n",
    "      return img\n",
    "\n",
    "\n",
    "    def get_object_bbox(self, obj_id):\n",
    "      object_indices = np.argwhere(self.instance_map == obj_id)\n",
    "      if object_indices.size > 0:\n",
    "          x_min, y_min = object_indices.min(axis=0)\n",
    "          x_max, y_max = object_indices.max(axis=0)\n",
    "          return (y_min, x_min, y_max, x_max)  # (y_min, x_min) to (y_max, x_max) for rectangle\n",
    "      return None\n",
    "\n",
    "\n",
    "# Create the environment\n",
    "env = ObjectHuntEnv()\n",
    "\n",
    "# Train the agent using PPO\n",
    "model = PPO(\"MlpPolicy\", env, learning_rate=0.00005, ent_coef=0.005, verbose=1)\n",
    "model.learn(total_timesteps=100000)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"ppo_object_hunt_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"ppo_object_hunt_weights\")\n",
    "\n",
    "\n",
    "env = ObjectHuntEnv(max_steps=50000)\n",
    "obs = env.reset()\n",
    "frames = []\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "\n",
    "    frame = env.render()\n",
    "\n",
    "    cv2.putText(frame, f\"Obj count: {len(env.collected_objects)}\", (5, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(frame, f\"Steps: {env.steps}\", (5, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    frames.append(frame)\n",
    "\n",
    "height, width, _ = frames[0].shape\n",
    "out = cv2.VideoWriter('ppo_object_hunt_28.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (width, height))\n",
    "\n",
    "for frame in frames:\n",
    "    out.write(frame)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "habitat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
